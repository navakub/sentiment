{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinnSentiment\n",
    "\n",
    "Neural Network implementation of sentiment analysis using **FinnSentiment** dataset from https://github.com/cynarr/sentiment-analysis/tree/master/data-raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Windows\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import essential packages for the project\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read data from a file\n",
    "def process_data(datatype, language, label):\n",
    "    '''\n",
    "        input:\n",
    "            - datatype: 'train' or 'test'\n",
    "            - language: 'en'(English) or 'fi'(Finnish)\n",
    "            - label: 'pos'(positive) or 'neg'(negative)\n",
    "        output:\n",
    "            - list of sentences\n",
    "    '''\n",
    "    filename = label + '_test.txt' if datatype=='test' else label + '.txt'\n",
    "    filepath = 'data-raw/bin/' + language + '/' + datatype + '/' + filename\n",
    "\n",
    "    with open(filepath, mode='r', encoding='utf8') as f:\n",
    "        sentences = f.readlines()\n",
    "\n",
    "    # -------------------------------------------------- data preprocessing  -------------------------------------------------- #\n",
    "    processed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower() # lowercase\n",
    "        sentence = sentence.replace('\\n','') # remove \\n  \n",
    "\n",
    "        words = word_tokenize(sentence) # tokenisation\n",
    "        # remove non-alphabet characters and punctuations\n",
    "        for word in words:\n",
    "            if (word in list(punctuation)) or word.isalpha()==False: \n",
    "                words.remove(word)\n",
    "                \n",
    "        # append list of words of a sentence to data\n",
    "        processed.append(words)\n",
    "    # -------------------------------------------------- data preprocessing  -------------------------------------------------- #\n",
    "\n",
    "    pol = 1 if label == 'pos' else 0 #polarity\n",
    "    processed = [(sentence, pol) for sentence in processed]\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing successful!\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing: get list of words for each sentence\n",
    "train_pos = process_data('train','fi','pos')\n",
    "train_neg = process_data('train','fi','neg')\n",
    "test_pos = process_data('test','fi','pos')\n",
    "test_neg = process_data('test','fi','neg')\n",
    "\n",
    "print('preprocessing successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_pos + train_neg\n",
    "test = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, label_train = [e[0] for e in train], [e[1] for e in train]\n",
    "input_test, label_test = [e[0] for e in test], [e[1] for e in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 9066 unique words in the corpus\n"
     ]
    }
   ],
   "source": [
    "corpus = set([word for e in input_train for word in e])\n",
    "vocab_size = len(corpus)\n",
    "print('there are %d unique words in the corpus' %(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    6427.000000\n",
       "mean        4.680878\n",
       "std         2.456990\n",
       "min         1.000000\n",
       "25%         3.000000\n",
       "50%         4.000000\n",
       "75%         6.000000\n",
       "max        25.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "length = [len(e) for e in input_train + input_test]\n",
    "maxlen = max(length)\n",
    "seq_len = maxlen\n",
    "\n",
    "pd.Series(length).hist()\n",
    "plt.show()\n",
    "pd.Series(length).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad / add unknown\n",
    "pad = '<PAD>'\n",
    "unk = '<UNK>'\n",
    "\n",
    "input_train_mod = list()\n",
    "for sentence in input_train:\n",
    "    sentence_padded = sentence\n",
    "    for j in range(seq_len):\n",
    "        if j >= len(sentence):\n",
    "            sentence_padded.append(pad)\n",
    "    input_train_mod.append(sentence_padded)\n",
    "\n",
    "input_test_mod= list()\n",
    "for sentence in input_test:\n",
    "    s = []\n",
    "    for j in range(seq_len):\n",
    "        if j >= len(sentence):\n",
    "            s.append(pad)\n",
    "        else:  \n",
    "            word = sentence[j]\n",
    "            if word not in corpus:\n",
    "                s.append(unk)\n",
    "            else:\n",
    "                s.append(word)\n",
    "    input_test_mod.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5774, 25)"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_train), len(input_train[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = input_train_mod\n",
    "input_test = input_test_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = {w:i+2 for i,w in enumerate(corpus)}\n",
    "\n",
    "pad_val = 0\n",
    "unk_val = 1\n",
    "encoder[pad] = pad_val\n",
    "encoder[unk] = unk_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "ipt_tr = []\n",
    "for sentence in input_train:\n",
    "    s = []\n",
    "    for word in sentence:\n",
    "        s.append(encoder[word])\n",
    "    ipt_tr.append(s) \n",
    "\n",
    "ipt_t = []\n",
    "for sentence in input_test:\n",
    "    s = []\n",
    "    for word in sentence:\n",
    "        s.append(encoder[word])\n",
    "    ipt_t.append(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "ipt_tr = ipt_tr\n",
    "lab_tr = label_train\n",
    "\n",
    "# test\n",
    "ipt_t = ipt_t\n",
    "lab_t = label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipt_tr, ipt_val, lab_tr, lab_val  = train_test_split(ipt_tr, lab_tr, test_size=0.2, random_state=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/nerd-for-tech/what-is-lstm-peephole-lstm-and-gru-77470d84954b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_17 (Embedding)    (None, 25, 64)            580352    \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 64)                24960     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 605377 (2.31 MB)\n",
      "Trainable params: 605377 (2.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "no_layers = 2\n",
    "vocab_size = len(corpus) + 2 # <PAD> and <UNK>\n",
    "embedding_dim = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "dropout = 0.5\n",
    "\n",
    "model = Sequential() \n",
    "model.add(Input(shape=(seq_len,)))\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=seq_len)) \n",
    "model.add(GRU(embedding_dim)) # lstm from keras\n",
    "\n",
    "\n",
    "model.add(Dropout(dropout)) \n",
    "model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93/93 [==============================] - 5s 29ms/step - loss: 0.6887 - accuracy: 0.5516 - val_loss: 0.6881 - val_accuracy: 0.5544\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.6876 - accuracy: 0.5577 - val_loss: 0.6874 - val_accuracy: 0.5544\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.6876 - accuracy: 0.5577 - val_loss: 0.6885 - val_accuracy: 0.5544\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6863 - accuracy: 0.5577 - val_loss: 0.6881 - val_accuracy: 0.5544\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6877 - accuracy: 0.5577 - val_loss: 0.6873 - val_accuracy: 0.5544\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6871 - accuracy: 0.5577 - val_loss: 0.6878 - val_accuracy: 0.5544\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.6875 - accuracy: 0.5575 - val_loss: 0.6875 - val_accuracy: 0.5544\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.6877 - accuracy: 0.5577 - val_loss: 0.6878 - val_accuracy: 0.5544\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6874 - accuracy: 0.5577 - val_loss: 0.6872 - val_accuracy: 0.5544\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.6676 - accuracy: 0.5767 - val_loss: 0.6294 - val_accuracy: 0.6677\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3768 - accuracy: 0.8511 - val_loss: 0.6904 - val_accuracy: 0.7106\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.1240 - accuracy: 0.9578 - val_loss: 0.8426 - val_accuracy: 0.7060\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.0620 - accuracy: 0.9812 - val_loss: 0.9267 - val_accuracy: 0.6983\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 2s 20ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 1.0467 - val_accuracy: 0.6738\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.0236 - accuracy: 0.9937 - val_loss: 1.4598 - val_accuracy: 0.6830\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 1.6849 - val_accuracy: 0.6922\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 1.6749 - val_accuracy: 0.6845\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.0058 - accuracy: 0.9978 - val_loss: 1.8517 - val_accuracy: 0.6876\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 1.5669 - val_accuracy: 0.6815\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 1.8117 - val_accuracy: 0.6907\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 6.2648e-04 - accuracy: 0.9998 - val_loss: 2.3287 - val_accuracy: 0.6753\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 2.8959e-04 - accuracy: 1.0000 - val_loss: 2.4433 - val_accuracy: 0.6784\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 2.4359e-04 - accuracy: 1.0000 - val_loss: 2.6826 - val_accuracy: 0.6677\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 2.4726 - val_accuracy: 0.6769\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 2.1878 - val_accuracy: 0.6799\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 1.6602 - val_accuracy: 0.6769\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 2.1125 - val_accuracy: 0.6753\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 2.2931 - val_accuracy: 0.6723\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.5243e-04 - accuracy: 1.0000 - val_loss: 2.4466 - val_accuracy: 0.6753\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0621e-04 - accuracy: 1.0000 - val_loss: 2.5409 - val_accuracy: 0.6723\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 8.8511e-05 - accuracy: 1.0000 - val_loss: 2.6089 - val_accuracy: 0.6723\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 8.0643e-05 - accuracy: 1.0000 - val_loss: 2.6653 - val_accuracy: 0.6738\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 6.9011e-05 - accuracy: 1.0000 - val_loss: 2.7180 - val_accuracy: 0.6738\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 6.0731e-05 - accuracy: 1.0000 - val_loss: 2.7628 - val_accuracy: 0.6738\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 5.9399e-05 - accuracy: 1.0000 - val_loss: 2.8113 - val_accuracy: 0.6738\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 5.0268e-05 - accuracy: 1.0000 - val_loss: 2.8497 - val_accuracy: 0.6738\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 5.3876e-05 - accuracy: 1.0000 - val_loss: 2.8898 - val_accuracy: 0.6723\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 4.7519e-05 - accuracy: 1.0000 - val_loss: 2.9319 - val_accuracy: 0.6723\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 4.4553e-05 - accuracy: 1.0000 - val_loss: 2.9702 - val_accuracy: 0.6738\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 3.9702e-05 - accuracy: 1.0000 - val_loss: 3.0065 - val_accuracy: 0.6738\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 3.9069e-05 - accuracy: 1.0000 - val_loss: 3.0407 - val_accuracy: 0.6738\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 3.4408e-05 - accuracy: 1.0000 - val_loss: 3.0738 - val_accuracy: 0.6753\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 3.2761e-05 - accuracy: 1.0000 - val_loss: 3.1057 - val_accuracy: 0.6738\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 3.0602e-05 - accuracy: 1.0000 - val_loss: 3.1357 - val_accuracy: 0.6738\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 2.9932e-05 - accuracy: 1.0000 - val_loss: 3.1666 - val_accuracy: 0.6738\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 2.5159e-05 - accuracy: 1.0000 - val_loss: 3.1953 - val_accuracy: 0.6738\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 2s 19ms/step - loss: 2.9386e-05 - accuracy: 1.0000 - val_loss: 3.2268 - val_accuracy: 0.6738\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 2s 18ms/step - loss: 2.4376e-05 - accuracy: 1.0000 - val_loss: 3.2560 - val_accuracy: 0.6738\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 2.3050e-05 - accuracy: 1.0000 - val_loss: 3.2838 - val_accuracy: 0.6738\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 2.5357e-05 - accuracy: 1.0000 - val_loss: 3.3135 - val_accuracy: 0.6738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21c771bbb80>"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 50\n",
    "\n",
    "model.fit(ipt_tr, lab_tr, validation_data=(ipt_t, lab_t), epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 10ms/step - loss: 3.3135 - accuracy: 0.6738\n"
     ]
    }
   ],
   "source": [
    "model_eval = model.evaluate(ipt_t, lab_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('lstm-finnsentiment-keras.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 model prediction testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(ipt_t).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(predictions)):\n",
    "    pred = predictions[i]\n",
    "    if pred > 0.5:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6738131699846861"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(lab_t, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 unseen prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user prediction\n",
    "def user_input_processing(review):\n",
    "    to_predict = []\n",
    "\n",
    "    review_text = review\n",
    "\n",
    "    # preprocess the review\n",
    "    to_predict = []\n",
    "    for word in review.split(\" \"):\n",
    "        word = str.lower(word)\n",
    "        if word[-1] == \".\":\n",
    "            word = word[:-1]\n",
    "        if word not in corpus:\n",
    "            word = unk\n",
    "        to_predict.append(encoder[word])\n",
    "    to_predict = pad_sequences([to_predict], seq_len, padding='post')\n",
    "\n",
    "    pol = 'positive' if model.predict(np.array(to_predict))[0] > 0.5 else 'negative'\n",
    "    \n",
    "    print(review_text)\n",
    "    print(pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n",
      "Saat yhdeksän yhdestä paketista, koska olen hyvällä tuulella.\n",
      "positive\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "täydellinen ruoka\n",
      "positive\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "se ei ole niin hyvä kuin luulin\n",
      "negative\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "Ennustettavaa ja huonoa. Näyttelijätyö oli kauheaa ja tarina yhteinen\n",
      "negative\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "huonot palvelut\n",
      "negative\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Olet niin kaunis.\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    'Saat yhdeksän yhdestä paketista, koska olen hyvällä tuulella.', # You get nine out of one pack because I'm in a good mood\n",
    "    'täydellinen ruoka', # 'perfect food' \n",
    "    'se ei ole niin hyvä kuin luulin', # 'it is not as good as i thought' \n",
    "    'Ennustettavaa ja huonoa. Näyttelijätyö oli kauheaa ja tarina yhteinen', # 'Predictable and bad. The acting was terrible and the story was common.'\n",
    "    'huonot palvelut', # 'bad services' \n",
    "    'Olet niin kaunis.' # 'you are so beautiful' \n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    user_input_processing(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
