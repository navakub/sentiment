{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinnSentiment\n",
    "\n",
    "Neural Network implementation of sentiment analysis using **FinnSentiment** dataset from https://github.com/cynarr/sentiment-analysis/tree/master/data-raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Windows\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import essential packages for the project\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read data from a file\n",
    "def process_data(datatype, language, label):\n",
    "    '''\n",
    "        input:\n",
    "            - datatype: 'train' or 'test'\n",
    "            - language: 'en'(English) or 'fi'(Finnish)\n",
    "            - label: 'pos'(positive) or 'neg'(negative)\n",
    "        output:\n",
    "            - list of sentences\n",
    "    '''\n",
    "    filename = label + '_test.txt' if datatype=='test' else label + '.txt'\n",
    "    filepath = 'data-raw/bin/' + language + '/' + datatype + '/' + filename\n",
    "\n",
    "    with open(filepath, mode='r', encoding='utf8') as f:\n",
    "        sentences = f.readlines()\n",
    "\n",
    "    # -------------------------------------------------- data preprocessing  -------------------------------------------------- #\n",
    "    processed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower() # lowercase\n",
    "        sentence = sentence.replace('\\n','') # remove \\n  \n",
    "\n",
    "        words = word_tokenize(sentence) # tokenisation\n",
    "        # remove non-alphabet characters and punctuations\n",
    "        for word in words:\n",
    "            if (word in list(punctuation)) or word.isalpha()==False: \n",
    "                words.remove(word)\n",
    "                \n",
    "        # append list of words of a sentence to data\n",
    "        processed.append(words)\n",
    "    # -------------------------------------------------- data preprocessing  -------------------------------------------------- #\n",
    "\n",
    "    pol = 1 if label == 'pos' else 0 #polarity\n",
    "    processed = [(sentence, pol) for sentence in processed]\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing successful!\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing: get list of words for each sentence\n",
    "train_pos = process_data('train','fi','pos')\n",
    "train_neg = process_data('train','fi','neg')\n",
    "test_pos = process_data('test','fi','pos')\n",
    "test_neg = process_data('test','fi','neg')\n",
    "\n",
    "print('preprocessing successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_pos + train_neg\n",
    "test = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, label_train = [e[0] for e in train], [e[1] for e in train]\n",
    "input_test, label_test = [e[0] for e in test], [e[1] for e in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 9066 unique words in the corpus\n"
     ]
    }
   ],
   "source": [
    "corpus = set([word for e in input_train for word in e])\n",
    "vocab_size = len(corpus)\n",
    "print('there are %d unique words in the corpus' %(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    6427.000000\n",
       "mean        4.680878\n",
       "std         2.456990\n",
       "min         1.000000\n",
       "25%         3.000000\n",
       "50%         4.000000\n",
       "75%         6.000000\n",
       "max        25.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "length = [len(e) for e in input_train + input_test]\n",
    "maxlen = max(length)\n",
    "seq_len = maxlen\n",
    "\n",
    "pd.Series(length).hist()\n",
    "plt.show()\n",
    "pd.Series(length).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad / add unknown\n",
    "pad = '<PAD>'\n",
    "unk = '<UNK>'\n",
    "\n",
    "input_train_mod = list()\n",
    "for sentence in input_train:\n",
    "    sentence_padded = sentence\n",
    "    for j in range(seq_len):\n",
    "        if j >= len(sentence):\n",
    "            sentence_padded.append(pad)\n",
    "    input_train_mod.append(sentence_padded)\n",
    "\n",
    "input_test_mod= list()\n",
    "for sentence in input_test:\n",
    "    s = []\n",
    "    for j in range(seq_len):\n",
    "        if j >= len(sentence):\n",
    "            s.append(pad)\n",
    "        else:  \n",
    "            word = sentence[j]\n",
    "            if word not in corpus:\n",
    "                s.append(unk)\n",
    "            else:\n",
    "                s.append(word)\n",
    "    input_test_mod.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5774, 25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_train), len(input_train[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = input_train_mod\n",
    "input_test = input_test_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = {w:i+2 for i,w in enumerate(corpus)}\n",
    "\n",
    "pad_val = 0\n",
    "unk_val = 1\n",
    "encoder[pad] = pad_val\n",
    "encoder[unk] = unk_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "ipt_tr = []\n",
    "for sentence in input_train:\n",
    "    s = []\n",
    "    for word in sentence:\n",
    "        s.append(encoder[word])\n",
    "    ipt_tr.append(s) \n",
    "\n",
    "ipt_t = []\n",
    "for sentence in input_test:\n",
    "    s = []\n",
    "    for word in sentence:\n",
    "        s.append(encoder[word])\n",
    "    ipt_t.append(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "ipt_tr = ipt_tr\n",
    "lab_tr = label_train\n",
    "\n",
    "# test\n",
    "ipt_t = ipt_t\n",
    "lab_t = label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipt_tr, ipt_val, lab_tr, lab_val  = train_test_split(ipt_tr, lab_tr, test_size=0.2, random_state=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, GRU, Dense, Dropout\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/nerd-for-tech/what-is-lstm-peephole-lstm-and-gru-77470d84954b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 64)            580352    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                24960     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 605377 (2.31 MB)\n",
      "Trainable params: 605377 (2.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "no_layers = 2\n",
    "vocab_size = len(corpus) + 2 # <PAD> and <UNK>\n",
    "embedding_dim = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "dropout = 0.5\n",
    "\n",
    "model = Sequential() \n",
    "model.add(Input(shape=(seq_len,)))\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=seq_len)) \n",
    "model.add(GRU(embedding_dim)) # gru from keras\n",
    "\n",
    "\n",
    "model.add(Dropout(dropout)) \n",
    "model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "93/93 [==============================] - 4s 18ms/step - loss: 0.6882 - accuracy: 0.5512 - val_loss: 0.6876 - val_accuracy: 0.5544\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.6877 - accuracy: 0.5579 - val_loss: 0.6872 - val_accuracy: 0.5544\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.6871 - accuracy: 0.5573 - val_loss: 0.6879 - val_accuracy: 0.5544\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.6871 - accuracy: 0.5577 - val_loss: 0.6874 - val_accuracy: 0.5544\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.6874 - accuracy: 0.5575 - val_loss: 0.6873 - val_accuracy: 0.5544\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.6879 - accuracy: 0.5577 - val_loss: 0.6872 - val_accuracy: 0.5544\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.6877 - accuracy: 0.5577 - val_loss: 0.6872 - val_accuracy: 0.5544\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.6876 - accuracy: 0.5577 - val_loss: 0.6874 - val_accuracy: 0.5544\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.6864 - accuracy: 0.5577 - val_loss: 0.6872 - val_accuracy: 0.5544\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.6654 - accuracy: 0.5830 - val_loss: 0.6103 - val_accuracy: 0.6799\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.3536 - accuracy: 0.8614 - val_loss: 0.6234 - val_accuracy: 0.7014\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.1310 - accuracy: 0.9584 - val_loss: 0.7714 - val_accuracy: 0.6876\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0601 - accuracy: 0.9833 - val_loss: 0.8757 - val_accuracy: 0.6998\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 1.0494 - val_accuracy: 0.6876\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 1.3940 - val_accuracy: 0.6861\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 1.3065 - val_accuracy: 0.6815\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 1.5171 - val_accuracy: 0.6723\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 1.6266 - val_accuracy: 0.6753\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 1.7802 - val_accuracy: 0.6692\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 2.0229 - val_accuracy: 0.6677\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 1.6882 - val_accuracy: 0.6815\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 1.9539 - val_accuracy: 0.6708\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 1.4738 - val_accuracy: 0.6953\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 1.5243 - val_accuracy: 0.6799\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 1.9506 - val_accuracy: 0.6799\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 1.7849 - val_accuracy: 0.6830\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 1.8413 - val_accuracy: 0.6799\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 1.9504 - val_accuracy: 0.6876\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 1.9122 - val_accuracy: 0.6907\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 4.2557e-04 - accuracy: 1.0000 - val_loss: 2.2654 - val_accuracy: 0.6861\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 2.9740e-04 - accuracy: 1.0000 - val_loss: 2.4170 - val_accuracy: 0.6845\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 1s 14ms/step - loss: 1.3209e-04 - accuracy: 1.0000 - val_loss: 2.4993 - val_accuracy: 0.6845\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 1s 14ms/step - loss: 1.0278e-04 - accuracy: 1.0000 - val_loss: 2.5690 - val_accuracy: 0.6861\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 9.1049e-05 - accuracy: 1.0000 - val_loss: 2.6269 - val_accuracy: 0.6845\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 7.8082e-05 - accuracy: 1.0000 - val_loss: 2.6817 - val_accuracy: 0.6845\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 7.4850e-05 - accuracy: 1.0000 - val_loss: 2.7300 - val_accuracy: 0.6845\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 1s 12ms/step - loss: 6.2189e-05 - accuracy: 1.0000 - val_loss: 2.7724 - val_accuracy: 0.6830\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 6.5057e-05 - accuracy: 1.0000 - val_loss: 2.8167 - val_accuracy: 0.6845\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 4.8953e-05 - accuracy: 1.0000 - val_loss: 2.8530 - val_accuracy: 0.6845\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 4.9897e-05 - accuracy: 1.0000 - val_loss: 2.8938 - val_accuracy: 0.6830\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 4.4376e-05 - accuracy: 1.0000 - val_loss: 2.9324 - val_accuracy: 0.6830\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 3.8788e-05 - accuracy: 1.0000 - val_loss: 2.9650 - val_accuracy: 0.6830\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 4.0808e-05 - accuracy: 1.0000 - val_loss: 2.9991 - val_accuracy: 0.6815\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 3.8321e-05 - accuracy: 1.0000 - val_loss: 3.0327 - val_accuracy: 0.6815\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 3.2693e-05 - accuracy: 1.0000 - val_loss: 3.0634 - val_accuracy: 0.6815\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 3.5405e-05 - accuracy: 1.0000 - val_loss: 3.0956 - val_accuracy: 0.6815\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 2.9284e-05 - accuracy: 1.0000 - val_loss: 3.1245 - val_accuracy: 0.6815\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 3.2767e-05 - accuracy: 1.0000 - val_loss: 3.1552 - val_accuracy: 0.6815\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 2.4794e-05 - accuracy: 1.0000 - val_loss: 3.1822 - val_accuracy: 0.6815\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 1s 13ms/step - loss: 2.4976e-05 - accuracy: 1.0000 - val_loss: 3.2105 - val_accuracy: 0.6815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x249ada09f30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 50\n",
    "\n",
    "model.fit(ipt_tr, lab_tr, validation_data=(ipt_t, lab_t), epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 3.2105 - accuracy: 0.6815\n"
     ]
    }
   ],
   "source": [
    "model_eval = model.evaluate(ipt_t, lab_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('gru-finnsentiment.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 model prediction testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(ipt_t).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(predictions)):\n",
    "    pred = predictions[i]\n",
    "    if pred > 0.5:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6814701378254211"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(lab_t, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 unseen prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user prediction\n",
    "def user_input_processing(review):\n",
    "    to_predict = []\n",
    "\n",
    "    review_text = review\n",
    "\n",
    "    # preprocess the review\n",
    "    to_predict = []\n",
    "    for word in review.split(\" \"):\n",
    "        word = str.lower(word)\n",
    "        if word[-1] == \".\":\n",
    "            word = word[:-1]\n",
    "        if word not in corpus:\n",
    "            word = unk\n",
    "        to_predict.append(encoder[word])\n",
    "    to_predict = pad_sequences([to_predict], seq_len, padding='post')\n",
    "\n",
    "    pol = 'positive' if model.predict(np.array(to_predict))[0] > 0.5 else 'negative'\n",
    "    \n",
    "    print(review_text)\n",
    "    print(pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saat yhdeksän yhdestä paketista, koska olen hyvällä tuulella.\n",
      "positive\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "täydellinen ruoka\n",
      "positive\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "se ei ole niin hyvä kuin luulin\n",
      "negative\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Ennustettavaa ja huonoa. Näyttelijätyö oli kauheaa ja tarina yhteinen\n",
      "negative\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "huonot palvelut\n",
      "positive\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Olet niin kaunis.\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    'Saat yhdeksän yhdestä paketista, koska olen hyvällä tuulella.', # You get nine out of one pack because I'm in a good mood\n",
    "    'täydellinen ruoka', # 'perfect food' \n",
    "    'se ei ole niin hyvä kuin luulin', # 'it is not as good as i thought' \n",
    "    'Ennustettavaa ja huonoa. Näyttelijätyö oli kauheaa ja tarina yhteinen', # 'Predictable and bad. The acting was terrible and the story was common.'\n",
    "    'huonot palvelut', # 'bad services' \n",
    "    'Olet niin kaunis.' # 'you are so beautiful' \n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    user_input_processing(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
