{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinnSentiment\n",
    "\n",
    "Neural Network implementation of sentiment analysis using **FinnSentiment** dataset from https://github.com/cynarr/sentiment-analysis/tree/master/data-raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Windows\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import essential packages for the project\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read data from a file\n",
    "def process_data(datatype, language, label):\n",
    "    '''\n",
    "        input:\n",
    "            - datatype: 'train' or 'test'\n",
    "            - language: 'en'(English) or 'fi'(Finnish)\n",
    "            - label: 'pos'(positive) or 'neg'(negative)\n",
    "        output:\n",
    "            - list of sentences\n",
    "    '''\n",
    "    filename = label + '_test.txt' if datatype=='test' else label + '.txt'\n",
    "    filepath = 'data-raw/bin/' + language + '/' + datatype + '/' + filename\n",
    "\n",
    "    with open(filepath, mode='r', encoding='utf8') as f:\n",
    "        sentences = f.readlines()\n",
    "\n",
    "    # -------------------------------------------------- data preprocessing  -------------------------------------------------- #\n",
    "    processed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower() # lowercase\n",
    "        sentence = sentence.replace('\\n','') # remove \\n  \n",
    "\n",
    "        words = word_tokenize(sentence) # tokenisation\n",
    "        # remove non-alphabet characters and punctuations\n",
    "        for word in words:\n",
    "            if (word in list(punctuation)) or word.isalpha()==False: \n",
    "                words.remove(word)\n",
    "                \n",
    "        # append list of words of a sentence to data\n",
    "        processed.append(words)\n",
    "    # -------------------------------------------------- data preprocessing  -------------------------------------------------- #\n",
    "\n",
    "    pol = 1 if label == 'pos' else 0 #polarity\n",
    "    processed = [(sentence, pol) for sentence in processed]\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing successful!\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing: get list of words for each sentence\n",
    "train_pos = process_data('train','fi','pos')\n",
    "train_neg = process_data('train','fi','neg')\n",
    "test_pos = process_data('test','fi','pos')\n",
    "test_neg = process_data('test','fi','neg')\n",
    "\n",
    "print('preprocessing successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_pos + train_neg\n",
    "test = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, label_train = [e[0] for e in train], [e[1] for e in train]\n",
    "input_test, label_test = [e[0] for e in test], [e[1] for e in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 9066 unique words in the corpus\n"
     ]
    }
   ],
   "source": [
    "corpus = set([word for e in input_train for word in e])\n",
    "vocab_size = len(corpus)\n",
    "print('there are %d unique words in the corpus' %(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    6427.000000\n",
       "mean        4.680878\n",
       "std         2.456990\n",
       "min         1.000000\n",
       "25%         3.000000\n",
       "50%         4.000000\n",
       "75%         6.000000\n",
       "max        25.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "length = [len(e) for e in input_train + input_test]\n",
    "maxlen = max(length)\n",
    "seq_len = maxlen\n",
    "\n",
    "pd.Series(length).hist()\n",
    "plt.show()\n",
    "pd.Series(length).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad / add unknown\n",
    "pad = '<PAD>'\n",
    "unk = '<UNK>'\n",
    "\n",
    "input_train_mod = list()\n",
    "for sentence in input_train:\n",
    "    sentence_padded = sentence\n",
    "    for j in range(seq_len):\n",
    "        if j >= len(sentence):\n",
    "            sentence_padded.append(pad)\n",
    "    input_train_mod.append(sentence_padded)\n",
    "\n",
    "input_test_mod= list()\n",
    "for sentence in input_test:\n",
    "    s = []\n",
    "    for j in range(seq_len):\n",
    "        if j >= len(sentence):\n",
    "            s.append(pad)\n",
    "        else:  \n",
    "            word = sentence[j]\n",
    "            if word not in corpus:\n",
    "                s.append(unk)\n",
    "            else:\n",
    "                s.append(word)\n",
    "    input_test_mod.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5774, 25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_train), len(input_train[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = input_train_mod\n",
    "input_test = input_test_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = {w:i+2 for i,w in enumerate(corpus)}\n",
    "\n",
    "pad_val = 0\n",
    "unk_val = 1\n",
    "one_hot_encoder[pad] = pad_val\n",
    "one_hot_encoder[unk] = unk_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "ipt_tr = []\n",
    "for sentence in input_train:\n",
    "    s = []\n",
    "    for word in sentence:\n",
    "        s.append(one_hot_encoder[word])\n",
    "    ipt_tr.append(s) \n",
    "\n",
    "ipt_t = []\n",
    "for sentence in input_test:\n",
    "    s = []\n",
    "    for word in sentence:\n",
    "        s.append(one_hot_encoder[word])\n",
    "    ipt_t.append(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "ipt_tr = ipt_tr\n",
    "lab_tr = label_train\n",
    "\n",
    "# test\n",
    "ipt_t = ipt_t\n",
    "lab_t = label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(ipt_tr), torch.tensor(lab_tr))\n",
    "test_dataset = TensorDataset(torch.tensor(ipt_t), torch.tensor(lab_t))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 25])\n",
      "Sample input: \n",
      " tensor([[5335, 2607,    0,  ...,    0,    0,    0],\n",
      "        [1561, 5466,  357,  ...,    0,    0,    0],\n",
      "        [2317, 3108,    0,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [6655, 6061, 7124,  ...,    0,    0,    0],\n",
      "        [4371, 8416, 4565,  ...,    0,    0,    0],\n",
      "        [7111, 6061, 1089,  ...,    0,    0,    0]])\n",
      "Sample output: \n",
      " tensor([0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample output: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model class (self-implementation)\n",
    "class lstm(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_len, hidden_len, num_layers, output_len, drop_prob=0.3):\n",
    "        super(lstm, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_len = embedding_len\n",
    "        self.hidden_len = hidden_len\n",
    "        self.num_layers = num_layers\n",
    "        self.output_len = output_len\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_len)\n",
    "        self.lstm = nn.LSTM(embedding_len, hidden_len, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_len, output_len)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embeds = self.embed(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_len)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sig(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros((self.num_layers, batch_size, self.hidden_len)).to(device)\n",
    "        c0 = torch.zeros((self.num_layers, batch_size, self.hidden_len)).to(device)\n",
    "        hidden = (h0,c0)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lstm(\n",
       "  (embed): Embedding(9067, 64)\n",
       "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "no_layers = 2\n",
    "vocab_size = len(corpus) + 2 #extra 1 for padding\n",
    "embedding_dim = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "\n",
    "model = lstm(vocab_size, embedding_dim, hidden_dim, no_layers, output_dim, drop_prob=0.3)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# loss and optimization functions\n",
    "lr = 0.001\n",
    "criterion = nn.BCELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the result\n",
    "def validate():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 16\u001b[0m output, h \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39msqueeze(), labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mlstm.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden):\n\u001b[1;32m---> 18\u001b[0m     embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     lstm_out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(embeds, hidden)\n\u001b[0;32m     20\u001b[0m     lstm_out \u001b[38;5;241m=\u001b[39m lstm_out\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_len)\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "counter = 0\n",
    "print_every = 1000\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    \n",
    "    h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        h = tuple([e.data for e in h])\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimiser.step()\n",
    "\n",
    "        if counter%print_every == 0:\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inp, lab in test_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                inp, lab = inp.to(device), lab.to(device)\n",
    "                out, val_h = model(inp, val_h)\n",
    "                val_loss = criterion(out.squeeze(), lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.689\n",
      "Test accuracy: 33.384 %\n"
     ]
    }
   ],
   "source": [
    "# Loading the best model\n",
    "model.load_state_dict(torch.load('./state_dict.pt'))\n",
    "\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "h = model.init_hidden(batch_size)\n",
    "\n",
    "model.eval()\n",
    "for inputs, labels in test_loader:\n",
    "    h = tuple([each.data for each in h])\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    output, h = model(inputs, h)\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    pred = torch.round(output.squeeze())  # Rounds the output to 0/1\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f} %\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_16568\\893722384.py:24: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), num_clips)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [279]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([each\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mfor\u001b[39;00m each \u001b[38;5;129;01min\u001b[39;00m h])\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 15\u001b[0m out,h  \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out\u001b[38;5;241m.\u001b[39msqueeze(), labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[1;32mIn [272]\u001b[0m, in \u001b[0;36mlstm.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden):\n\u001b[0;32m     16\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m     embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     lstm_out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(embeds, hidden)\n\u001b[0;32m     20\u001b[0m     lstm_out \u001b[38;5;241m=\u001b[39m lstm_out\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_len)\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "num_clips = 5\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    l = []\n",
    "    model.train()\n",
    "    \n",
    "    h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        out,h  = model(inputs, h)\n",
    "    \n",
    "        loss = criterion(out.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        l.append(loss.item())\n",
    "\n",
    "        metric = BinaryAccuracy()\n",
    "        val_accuracy = metric(out, labels)\n",
    "\n",
    "        nn.utils.clip_grad_norm(model.parameters(), num_clips)\n",
    "        optimiser.step()\n",
    "    \n",
    "\n",
    "    '''\n",
    "    model.eval()\n",
    "    \n",
    "    val_h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in val_loader:\n",
    "\n",
    "        val_inputs, val_labels = inputs.to(device), labels.to(device)\n",
    "        val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "        val_out,val_h = model(val_inputs, val_h)\n",
    "        val_loss = criterion(val_out.squeeze(), val_labels.float())\n",
    "\n",
    "        metric = BinaryAccuracy()\n",
    "        val_accuracy = metric(out, labels)\n",
    "        optimizer.step()\n",
    "    '''\n",
    "    \n",
    "\n",
    "    print(\"Epoch: %d, accuracy: %1.5f\" % (epoch, accuracy)) \n",
    "    print('loss: %1.5f' % (np.mean(l)))\n",
    "    print(20*'==')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@khang.pham.exxact/hugging-face-text-classification-tutorial-using-pytorch-cd3d6bc33292"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. model evaluation visulisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch_tr_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [989]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mepoch_tr_acc\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Acc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epoch_vl_acc, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Acc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epoch_tr_acc' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "plt.plot(epoch_vl_acc, label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "   \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_tr_loss, label='Train loss')\n",
    "plt.plot(epoch_vl_loss, label='Validation loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 testing and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
