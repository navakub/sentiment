{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinnSentiment\n",
    "\n",
    "Neural Network implementation of sentiment analysis using **FinnSentiment** dataset from https://github.com/cynarr/sentiment-analysis/tree/master/data-raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Binary Classifier\n",
    "In this section, we will consider only 2 polarities of the comments: **positive** and **negative**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%pip install numpy\\n%pip install matplotlib\\n%pip install nltk\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment to install packages\n",
    "'''\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install nltk\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Windows\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import essential packages for the project\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "%matplotlib inline\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Punctuation\n",
      "\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print('\\nPunctuation\\n')\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'a', 'girl', '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of how to use word_tokenize\n",
    "word_tokenize('I am a girl.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read data from a file\n",
    "def process_data(datatype, language, label):\n",
    "    '''\n",
    "        input:\n",
    "            - datatype: 'train' or 'test'\n",
    "            - language: 'en'(English) or 'fi'(Finnish)\n",
    "            - label: 'pos'(positive) or 'neg'(negative)\n",
    "        output:\n",
    "            - list of sentences\n",
    "    '''\n",
    "    filename = label + '_test.txt' if datatype=='test' else label + '.txt'\n",
    "    filepath = 'data-raw/bin/' + language + '/' + datatype + '/' + filename\n",
    "\n",
    "    with open(filepath, mode='r', encoding='utf8') as f:\n",
    "        sentences = f.readlines()\n",
    "\n",
    "    # -------------------------------------------------- data preprocessing  -------------------------------------------------- #\n",
    "    data = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower() # lowercase\n",
    "        sentence = sentence.replace('\\n','') # remove \\n  \n",
    "\n",
    "        words = word_tokenize(sentence) # tokenisation\n",
    "        # remove non-alphabet characters and punctuations\n",
    "        for word in words:\n",
    "            if (word in list(punctuation)) or word.isalpha()==False: \n",
    "                words.remove(word)\n",
    "                \n",
    "        # append list of words of a sentence to data\n",
    "        data.append(words)\n",
    "    # -------------------------------------------------- data preprocessing  -------------------------------------------------- #\n",
    "\n",
    "    pol = 1 if label == 'pos' else 0 #polarity\n",
    "    data = [(sentence, pol) for sentence in data]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing successful!\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing: get list of words for each sentence\n",
    "train_pos = process_data('train','fi','pos')\n",
    "train_neg = process_data('train','fi','neg')\n",
    "test_pos = process_data('test','fi','pos')\n",
    "test_neg = process_data('test','fi','neg')\n",
    "\n",
    "print('preprocessing successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5774, 653)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_pos + train_neg\n",
    "test = test_pos + test_neg\n",
    "\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data to reduce bias\n",
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "random.shuffle(train)\n",
    "random.shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5196, 578)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation set\n",
    "split = int(0.9*len(train))\n",
    "validate = train[split::]\n",
    "train = train[0:split]\n",
    "len(train), len(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate sentences and polarity\n",
    "def separate(all_list):\n",
    "    train_sentences = [e[0] for e in all_list]\n",
    "    train_pols = [e[1] for e in all_list]\n",
    "    return train_sentences, train_pols\n",
    "\n",
    "\n",
    "train_sentences, train_pols = separate(train)\n",
    "val_sentences, val_pols = separate(validate)\n",
    "test_sentences, test_pols = separate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = train_sentences + val_sentences + test_sentences\n",
    "all_pols= train_pols + val_pols + test_pols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAe3ElEQVR4nO3deZwdVZ3+8c9jwo4QlogQAkHBBTeMEXRAZYRBFh1wRXRkEc3PFXAZRZ1RdFxgVBRm1JFNAyIKiICCCiKIKCABAgSiPyIEkrCFfRuRwDN/1Gm5NN1d1ctdOv28X6/76qpTVae+fTu531vnVJ0j20RERAzlad0OICIiel+SRURE1EqyiIiIWkkWERFRK8kiIiJqJVlEREStJIsYEUmLJO3YhfPOkGRJk0d4/L6SLmpZf1DSs8Yotk9LOmYs4hyg7k1KrJPGor5hnHcDSRdKekDS19t0jndKOqcddcfYSbKIntbupGR7Tds31MSwvaQlDer6su33jEVc/X9v2zeXWB8bi/qHYTZwJ7CW7Y/13yjp+5K+OJoT2D7R9k6jqSPaL8kiYgyM1RVED9oUuM4jfHp3BX5fJpwkixg1SU+TdLCkv0i6S9LJktYt2/qaY/aRdLOkOyV9puXY1STNkXSPpAWSPtH3LV7SCcAmwM9KE8wnWk77zoHqGyC29SSdKel+SX8Ent1vuyVtXpZ3lXRdaXJZKunjktYAfgFsVGJ4UNJGkg6RdKqkH0i6H9i3lP2gXwjvlnSLpFslfbzlvE/6Rt569TLQ792/WavEcKakuyUtlPTelroOKX+D48vvcq2kWUO8R/8g6TJJ95Wf/9AXI7AP8IkSx479jpsNvLNl+89K+SJJn5R0NfCQpMkt/z4eKO/xG1vq6d80aEnvk3S9pHslfUuSBos/OsR2XnkN+wUsAnYsywcClwAbA6sA3wVOKttmAAaOBlYDXgI8Ajy/bD8U+C2wTjn+amDJQOdpUt8Acf4IOBlYA3ghsBS4qGW7gc3L8q3Aq8ryOsDMsrx9a0yl7BDgUWAPqi9dq5WyH/SL86Ry7hcBy1res+8DX2yp70nnGOL3nlzWLwS+DawKbFXqfm1LbH8FdgUmAV8BLhnk/VkXuAd4FzAZ2KusrzdQnAMc/5TtJfZ5wHRgtVL2VmCj8l7tCTwEbFi27TvA3+TnwBSqpLkM2Lnb/+Yn+itXFjEW3gd8xvYS249QfVi9pV8TxOdt/6/tq4CrqD7kAd4GfNn2PbaXAEc2POdg9f1d6Qx+M/BZ2w/Zng/MGaLOR4EtJa1V4rmiJoaLbZ9u+3Hb/ztEnA/Zvgb4HtWH8ahImg5sC3zS9l9tzwOOAfZu2e0i22e76uM4gQHen2I34HrbJ9hebvsk4E/AG0YZ5pG2F/e9L7ZPsX1Lea9+DFwPbD3E8Yfavtf2zcD5VAkxuijJIsbCpsBPS5PBvcAC4DFgg5Z9bmtZfhhYsyxvBCxu2da6PJTB6ms1lerbcmudNw1R55upvo3fJOm3kl5ZE0OTWPufe6MGx9TZCLjb9gP96p7Wst7//Vl1kP6DjXjqe9K/rpF40nsjaW9J81r+jbwQWH+I45v8faODkixiLCwGdrE9peW1qu2lDY69lar5qc/0fttHMyzyMmB5vzo3GWxn25fZ3h14BnA6VfPVUDE0ia3/uW8pyw8Bq7dse+Yw6r4FWFfS0/vV3eT9HqiuTfuVDaeu2vdG0qZUzYYfomremgLMB9IPMY4kWcRY+B/gS+VDAUlTJe3e8NiTgU9JWkfSNKoPlFa3AyN6DqI0wZwGHCJpdUlbUnXYPoWklVXd77+27UeB+4HHW2JYT9LaIwjj38u5XwDsB/y4lM8DdpW0rqRnAgf1O27Q39v2YuAPwFckrSrpxcD+QP/O9SbOBp4j6R2lI3pPYEuqPoMmmvx91qBKHssAJO1HdWUR40iSRYyFI4AzgXMkPUDV2b1Nw2O/ACwBbgR+DZxK1WHd5yvAv5Xmi48PcHydD1E1YdxG1Rn7vSH2fRewqNzd9D6qO32w/SeqjuobShzDaUr6LbAQOA/4mu2+h89OoOprWQScwxNJpE/d770XVaf3LcBPgc/Z/vUw4gLA9l3A64GPAXcBnwBeb/vOhlUcS9XPc6+k0wc5x3XA14GLqZLLi4DfDzfW6C7Zmfwoeoek9wNvt/2abscSEU/IlUV0laQNJW2r6lmN51J9w/1pt+OKiCfL05XRbStTPZexGXAv1XMR3+5mQBHxVGmGioiIWmmGioiIWitkM9T666/vGTNmdDuMiIhx5fLLL7/T9tSBtq2QyWLGjBnMnTu322FERIwrkgYd4SDNUBERUSvJIiIiaiVZRERErSSLiIiolWQRERG1kiwiIqJWkkVERNRKsoiIiFpJFhERUWuFfIJ7vJpx8FkjPnbRobuNYSQREU+WK4uIiKiVK4sxNpqrg4iIXpUri4iIqJVkERERtZIsIiKiVpJFRETUSrKIiIhaSRYREVErySIiImolWURERK0ki4iIqJVkERERtZIsIiKiVpJFRETUSrKIiIhaSRYREVErySIiImolWURERK0ki4iIqNW2ZCHpOEl3SJrfUraupHMlXV9+rlPKJelISQslXS1pZssx+5T9r5e0T7vijYiIwbXzyuL7wM79yg4GzrO9BXBeWQfYBdiivGYD34EquQCfA7YBtgY+15dgIiKic9qWLGxfCNzdr3h3YE5ZngPs0VJ+vCuXAFMkbQi8DjjX9t227wHO5akJKCIi2qzTfRYb2L61LN8GbFCWpwGLW/ZbUsoGK38KSbMlzZU0d9myZWMbdUTEBNe1Dm7bBjyG9R1le5btWVOnTh2raiMigs4ni9tL8xLl5x2lfCkwvWW/jUvZYOUREdFBnU4WZwJ9dzTtA5zRUr53uSvqFcB9pbnqV8BOktYpHds7lbKIiOigye2qWNJJwPbA+pKWUN3VdChwsqT9gZuAt5XdzwZ2BRYCDwP7Adi+W9J/AJeV/b5gu3+neUREtFnbkoXtvQbZtMMA+xr44CD1HAccN4ahRUTEMOUJ7oiIqJVkERERtZIsIiKiVpJFRETUSrKIiIhaSRYREVErySIiImolWURERK0ki4iIqJVkERERtZIsIiKiVpJFRETUSrKIiIhaSRYREVErySIiImolWURERK0ki4iIqJVkERERtYaVLCStI+nF7QomIiJ6U22ykHSBpLUkrQtcARwt6fD2hxYREb2iyZXF2rbvB94EHG97G2DH9oYVERG9pEmymCxpQ+BtwM/bHE9ERPSgJsniC8CvgL/YvkzSs4Dr2xtWRET0ksl1O9g+BTilZf0G4M3tDCoiInpLkw7u50g6T9L8sv5iSf/W/tAiIqJXNGmGOhr4FPAogO2rgbe3M6iIiOgtTZLF6rb/2K9seTuCiYiI3tQkWdwp6dmAASS9Bbi1rVFFRERPaZIsPgh8F3iepKXAQcD7R3NSSR+RdK2k+ZJOkrSqpM0kXSppoaQfS1q57LtKWV9Yts8YzbkjImL4apOF7Rts7whMBZ5nezvbi0Z6QknTgAOAWbZfCEyi6gM5DPiG7c2Be4D9yyH7A/eU8m+U/SIiooOa3A31ZUlTbD9k+4EyPtQXR3neycBqkiYDq1M1a70WOLVsnwPsUZZ3L+uU7TtI0ijPHxERw9CkGWoX2/f2rdi+B9h1pCe0vRT4GnAzVZK4D7gcuNd2X8f5EmBaWZ4GLC7HLi/7r9e/XkmzJc2VNHfZsmUjDS8iIgbQJFlMkrRK34qk1YBVhth/SJLWobpa2AzYCFgD2Hmk9fWxfZTtWbZnTZ06dbTVRUREi9onuIETgfMkfa+s78cTzUIjsSNwo+1lAJJOA7YFpkiaXK4eNgaWlv2XAtOBJaXZam3grlGcPyIihqlJB/dhwJeA55fXf9j+z1Gc82bgFZJWL30POwDXAecDbyn77AOcUZbPLOuU7b+x7VGcPyIihqnJlQW2fwH8YixOaPtSSadSzY2xHLgSOAo4C/hR6Ty/Eji2HHIscIKkhcDd5OnxiIiOU92XdElvorpd9RmAysu212p/eCMza9Ysz507tyvnnnHwWV0572gsOnS3bocQET1A0uW2Zw20rcmVxX8Cb7C9YGzDioiI8aLJ3VC3J1FERExsTa4s5kr6MXA68Ehfoe3T2hVURET0libJYi3gYWCnljIDSRYRERNEk5ny9utEIBER0bsyU15ERNTKTHkREVErM+VFREStzJQXERG1mtwN9UGq4Tj6Zsq7EXhnW6PqsvH4FHZERDs1SRa2vaOkNYCnlQmQNmt3YBER0TuaNEP9BKBvprxSduoQ+0dExApm0CsLSc8DXgCsXQYT7LMWsGq7A4uIiN4xVDPUc4HXA1OAN7SUPwC8t40xRUREjxk0Wdg+AzhD0ittX9zBmCIiosc06eBeKOnTwIzW/W2/u11BRUREb2mSLM4Afgf8GnisveFEREQvapIsVrf9ybZHEhERPavJrbM/l7Rr2yOJiIie1SRZHEiVMP4q6X5JD0i6v92BRURE72gyn8XTOxFIRET0ribzWUjSv0j697I+XdLW7Q8tIiJ6RZNmqG8DrwTeUdYfBL7VtogiIqLnNLkbahvbMyVdCWD7HkkrtzmuiIjoIU2uLB6VNIkn5rOYCjze1qgiIqKnNEkWRwI/BZ4h6UvARcCX2xpVRET0lCZ3Q50o6XJgB0DAHrYXtD2yiIjoGU3uhno2cKPtbwHzgX+SNKXdgUVERO9oOvnRY5I2B74LTAd+OJqTSpoi6VRJf5K0QNIrJa0r6VxJ15ef65R9JelISQslXS1p5mjOHRERw9ckWTxueznwJuC/bf8rsOEoz3sE8EvbzwNeAiwADgbOs70FcF5ZB9gF2KK8ZgPfGeW5IyJimJreDbUXsDfw81K20khPKGlt4NXAsQC2/2b7XmB3YE7ZbQ6wR1neHTjelUuAKZJGm6wiImIYmiSL/ageyvuS7RslbQacMIpzbgYsA74n6UpJx0haA9jA9q1ln9uADcryNGBxy/FLStmTSJotaa6kucuWLRtFeBER0V9tsrB9ne0DbJ9U1m+0fdgozjkZmAl8x/ZLgYd4osmp75ymPNfRlO2jbM+yPWvq1KmjCC8iIvprcmUx1pYAS2xfWtZPpUoet/c1L5Wfd5TtS6k61ftsXMoiIqJDOp4sbN8GLJb03FK0A3AdcCawTynbh2qGPkr53uWuqFcA97U0V0VERAcM+lCepBNsv0vSgbaPGOPzfhg4sYwxdQNVv8jTgJMl7Q/cBLyt7Hs2sCuwEHi47Bs9ZMbBZ4342EWH7jaGkUREuwz1BPfLJG0EvFvS8VRPb/+d7btHelLb84BZA2zaYYB9DXxwpOeKiIjRGypZ/A/V8w7PAi7nycnCpTwiIiaAQfssbB9p+/nAcbafZXuzllcSRUTEBNJkIMH3S3oJ8KpSdKHtq9sbVkRE9JImAwkeAJwIPKO8TpT04XYHFhERvaPJTHnvoZot7yEASYcBFwP/1c7AIiKidzR5zkLAYy3rj9HvzqiIiFixNbmy+B5wqaSflvU9KIMARkTExNCkg/twSRcA25Wi/Wxf2daoIiKipzS5ssD2FcAVbY4lIiJ6VDcGEoyIiHEmySIiImoNmSwkTZJ0fqeCiYiI3jRksrD9GPB4mQo1IiImqCYd3A8C10g6l2pWOwBsH9C2qKKjRjPEeERMDE2SxWnlFRERE1ST5yzmSFoN2MT2nzsQU0RE9JgmAwm+AZgH/LKsbyXpzDbHFRERPaTJrbOHAFsD98LfZ7nLfBYRERNIk2TxqO37+pU93o5gIiKiNzXp4L5W0juASZK2AA4A/tDesCIiopc0ubL4MPAC4BHgJOB+4KA2xhQRET2myd1QDwOfKZMe2fYD7Q8rIiJ6SZO7oV4u6RrgaqqH866S9LL2hxYREb2iSZ/FscAHbP8OQNJ2VBMivbidgUVERO9o0mfxWF+iALB9EbC8fSFFRESvGfTKQtLMsvhbSd+l6tw2sCdwQftDi4iIXjFUM9TX+61/rmXZbYglIiJ61KDJwvY/tvPEkiYBc4Gltl8vaTPgR8B6wOXAu2z/TdIqwPHAy4C7gD1tL2pnbBER8WRN7oaaIukASYdLOrLvNQbnPhBY0LJ+GPAN25sD9wD7l/L9gXtK+TfKfhER0UFNOrjPBmYA11B94+97jZikjYHdgGPKuoDXAqeWXeYAe5Tl3cs6ZfsOZf+IiOiQJrfOrmr7o2N83m8CnwCeXtbXA+613XeX1RJgWlmeBiwGsL1c0n1l/ztbK5Q0G5gNsMkmm4xxuBERE1uTK4sTJL1X0oaS1u17jfSEkl4P3GF7VFcn/dk+yvYs27OmTp06llVHREx4Ta4s/gZ8FfgMT9wFZUY+TPm2wD9L2hVYFVgLOAKYImlyubrYGFha9l8KTAeWSJoMrE3V0R0RER3S5MriY8DmtmfY3qy8Rjyfhe1P2d7Y9gzg7cBvbL8TOB94S9ltH+CMsnxmWads/43t3LobEdFBTZLFQuDhdgcCfBL4qKSFVH0Sx5byY4H1SvlHgYM7EEtERLRo0gz1EDBP0vlUw5QDYPuA0Z7c9gWUp8Ft30A1I1//ff4KvHW054qIiJFrkixOL6+IiJigmsxnMadun4iIWLHVJgtJNzLAWFCj6eSOiIjxpUkz1KyW5VWp+g9G/JxFRESMP7V3Q9m+q+W11PY3qYbqiIiICaJJM9TMltWnUV1pNLkiiYiIFUSTD/3WeS2WA4uAt7UlmoiI6ElN7oZq67wWERHR+5o0Q60CvJlqmPK/72/7C+0LKyIiekmTZqgzgPuo5rB4pGbfiIhYATVJFhvb3rntkURERM9qMpDgHyS9qO2RREREz2pyZbEdsG95kvsRQIBtv7itkUVERM9okix2aXsUERHR05rcOntTJwKJiIje1aTPIiIiJrgki4iIqJVkERERtZIsIiKiVpJFRETUSrKIiIhaSRYREVErySIiImolWURERK0ki4iIqJVkERERtZIsIiKiVpJFRETU6niykDRd0vmSrpN0raQDS/m6ks6VdH35uU4pl6QjJS2UdLWkmZ2OOSJiouvGlcVy4GO2twReAXxQ0pbAwcB5trcAzivrUM2nsUV5zQa+0/mQIyImto4nC9u32r6iLD8ALACmAbsDc8puc4A9yvLuwPGuXAJMkbRhZ6OOiJjYutpnIWkG8FLgUmAD27eWTbcBG5TlacDilsOWlLL+dc2WNFfS3GXLlrUv6IiICahryULSmsBPgINs39+6zbYBD6c+20fZnmV71tSpU8cw0oiI6EqykLQSVaI40fZppfj2vual8vOOUr4UmN5y+MalLCIiOqQbd0MJOBZYYPvwlk1nAvuU5X2AM1rK9y53Rb0CuK+luSoiIjpgchfOuS3wLuAaSfNK2aeBQ4GTJe0P3AS8rWw7G9gVWAg8DOzX0WgjIqLzycL2RYAG2bzDAPsb+GBbg4qIiCHlCe6IiKiVZBEREbW60WcR8XczDj5rxMcuOnS3MYwkIoaSK4uIiKiVZBEREbWSLCIiolaSRURE1EqyiIiIWkkWERFRK8kiIiJqJVlEREStJIuIiKiVZBEREbUy3EeMWxkqJKJzcmURERG1kiwiIqJWkkVERNRKsoiIiFpJFhERUSvJIiIiaiVZRERErSSLiIiolWQRERG18gR3TEijefob8gR4TDy5soiIiFq5sojosIxpFeNRkkXECIy2GStivEkzVERE1Bo3yULSzpL+LGmhpIO7HU9ExEQyLpqhJE0CvgX8E7AEuEzSmbav625kEZ3Vreav9JXEuEgWwNbAQts3AEj6EbA7kGQR0QHd7KNJouoN4yVZTAMWt6wvAbZp3UHSbGB2WX1Q0p/L8vrAnW2PcPgS1/AkruFZYeLSYW2K5MlWmPdrlDYdbMN4SRa1bB8FHNW/XNJc27O6ENKQEtfwJK7hSVzDk7jqjZcO7qXA9Jb1jUtZRER0wHhJFpcBW0jaTNLKwNuBM7scU0TEhDEumqFsL5f0IeBXwCTgONvXNjz8KU1TPSJxDU/iGp7ENTyJq4ZsdzuGiIjoceOlGSoiIrooySIiImqtsMmiV4cHkbSqpD9KukrStZI+3+2Y+kiaIulUSX+StEDSK3sgpgMlzS/v1UFdjuU4SXdImt9S9tXyfl0t6aeSpvRIXIdIWippXnnt2iNxbSXpkhLTXElbdyGu6ZLOl3Rd+Xd1YCl/a1l/XFLHb1cdLK6W7R+TZEnrdzo2AGyvcC+qTvC/AM8CVgauArbsdlwlNgFrluWVgEuBV3Q7rhLPHOA9ZXllYEqX43khMB9YnepmjF8Dm3cxnlcDM4H5LWU7AZPL8mHAYT0S1yHAx7v89xsornOAXcryrsAFXYhrQ2BmWX468P+BLYHnA88FLgBm9UpcZX061Q0+NwHrd+PvuaJeWfx9eBDbfwP6hgfpOlceLKsrlVfX7zKQtDbVf+5jAWz/zfa9XQ2q+s97qe2HbS8Hfgu8qVvB2L4QuLtf2TklNoBLqJ4B6npcvWCQuAysVZbXBm7paFCA7VttX1GWHwAWANNsL7D956GP7nxcZfM3gE/Qxc+KFTVZDDQ8yLRB9u04SZMkzQPuAM61fWmXQwLYDFgGfE/SlZKOkbRGl2OaD7xK0nqSVqf6Jjq95phuejfwi24H0eJDpXnsOEnrdDuY4iDgq5IWA18DPtXNYCTNAF5KdYXfM1rjkrQ7sNT2Vd2MaUVNFj3N9mO2t6L6Frq1pBd2OSSomnlmAt+x/VLgIaCrfT22F1A17ZwD/BKYBzzWzZgGI+kzwHLgxG7HUnwHeDawFXAr8PWuRvOE9wMfsT0d+AjlSrYbJK0J/AQ4yPb93Yqjv9a4qP5NfRr4bDdjghU3WYyL4UFKM8/5wM5dDgWqq68lLVc5p1Ilj66yfaztl9l+NXAPVTtuT5G0L/B64J0uDczdZvv28qXkceBoqqbZXrAPcFpZPoUuxSVpJaoP5BNtn1a3f6cMENezqa76r5K0iOqz7ApJz+x0bCtqsujZ4UEkTe27Y0bSalRzdPypq0EBtm8DFkt6binagR4YAl7SM8rPTaj6K37Y3YieTNLOVG3J/2z74W7H00fShi2rb6Rq0usFtwCvKcuvBa7vdACSRHVFs8D24Z0+/2AGisv2NbafYXuG7RlUX+pmlv+vnY2vR74Ijblyq+A3eWJ4kC91N6KKpBdT3XU0iSpZn2z7C92NqiJpK+AYqjuhbgD2s31Pl2P6HbAe8CjwUdvndTGWk4DtqYaNvh34HFWb+yrAXWW3S2y/rwfi2p6qCcrAIuD/2b61B+L6M3AEVbPnX4EP2L68w3FtB/wOuAZ4vBR/murv+F/AVOBeYJ7t13U7Lttnt+yziOpOrY4Pp77CJouIiBg7K2ozVEREjKEki4iIqJVkERERtZIsIiKiVpJFRETUSrKIcUXSg/V7DbvOrVpHZS0jtn58FPW9tYzae/7YRPiU+reX9A/tqDtiMEkWEdXzCGM5hPf+wHtt/+MY1tlqeyDJIjoqySLGLUn/KumyMlje50vZjPKt/ugyJ8A55Ul5JL287DuvzEMxvzzh/wVgz1K+Z6l+S0kXSLpB0gGDnH8vSdeUeg4rZZ8FtgOOlfTVfvtvKOnCcp75kl5VyneSdLGkKySdUsYGQtIiSZ8v5ddIel4ZYO59wEdKPa8qowL8pLwXl0nathx/SBlE8Cm/h6S9y3txlaQTStlg9bxGT8yLcaWkp4/F3y/GmW6Mi55XXiN9AQ+WnztRTWYvqi89P6caYn0G1eBrW5X9Tgb+pSzPB15Zlg+lzLMA7Av8d8s5DgH+QPVE7/pUT2ev1C+OjYCbqZ72nQz8BtijbLuAAeZDAD4GfKYsT6Kas2B94EJgjVL+SeCzZXkR8OGy/AHgmJb4Pt5S7w+B7cryJlTDRQz6ewAvoBpja/2y37o19fwM2LYsr0mZvyOvifWaXJNLInrVTuV1ZVlfE9iC6gP8RtvzSvnlwIwyHtfTbV9cyn9INfjfYM6y/QjwiKQ7gA2oxuXp83KqiXuWAUg6kSpZnT5EnZcBx5XB4k63PU/Sa6gm3vl9NTQQKwMXtxzTN8jd5Qw+l8eOVFdCfetr9V2dDPJ7vBY4xWXICNt319Tze+Dw8jueZrv1fYgJIskixisBX7H93ScVVs00j7QUPQasNoL6+9cx6v8rti+U9GpgN+D7kg6nGkn3XNt71cQxVAxPo5pt8a+theVDfzi/x4D1AIdKOouqX+f3kl5nu+uDX0Znpc8ixqtfAe9uad+f1jdC7UBcDQf/gKRtStHbWzY/QNUkNBx/BF4jaX1Jk4C9qGbyG5SkTYHbbR9NNWDjTKrZ9baVtHnZZw1Jz6k5d/94zwE+3HKerWqO/w3wVknrlf3XHaoeSc92NfrpYVRXR8+rqT9WQEkWMS7ZPoeqKeliSddQzb9R94G/P3C0qlkK1wDuK+XnUzW/tHZw153/VqrJoc6nmuP9cttn1By2PdW8BFcCewJHlGasfYGTJF1N1QRV92H8M+CNfR3cwAHArNJhfR1VB/hQsV8LfAn4raSrgL5huger56DSIX811ei/vTQbYHRIRp2NCUPSmi7zn0s6GNjQ9oFdDitiXEifRUwku0n6FNW/+5uovtFHRAO5soiIiFrps4iIiFpJFhERUSvJIiIiaiVZRERErSSLiIio9X96NY8jJcUXCwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sentence length distribution\n",
    "rev_len = [len(i) for i in train_sentences]\n",
    "\n",
    "plt.title('length distribution of train')\n",
    "plt.hist(rev_len, bins=20)\n",
    "plt.xlabel('length of sentences')\n",
    "plt.ylabel('number of sentences')\n",
    "plt.xticks(np.arange(0, 25, step=3))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "corpus = sum(all_sentences, [])\n",
    "counter_corpus = Counter(corpus)\n",
    "num_vocab = len(counter_corpus.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the longest sentence has 25 words\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(sentence) for sentence in train_sentences])\n",
    "print('the longest sentence has', max_len, 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word-to-index\n",
    "corpus_set = list(set(corpus))\n",
    "word2idx = {e: i+2 for i,e in enumerate(corpus_set)}\n",
    "\n",
    "padded_text = '[PAD]'\n",
    "word2idx[padded_text] = 0\n",
    "unknown_text = '[UNK]'\n",
    "word2idx[unknown_text] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index-to-word\n",
    "idx2word = dict((v,k) for k,v in word2idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(sentences):\n",
    "    '''\n",
    "    input:\n",
    "        - list of sentences\n",
    "    output:\n",
    "        - list of encoded sentences (tt)\n",
    "    '''\n",
    "    tt = []\n",
    "    for sentence in sentences:\n",
    "        new = []\n",
    "        for word in sentence:\n",
    "            new.append(word2idx[word])\n",
    "        if len(new) < max_len:\n",
    "            for _ in range(0, max_len - len(new)):\n",
    "                new.append(word2idx[padded_text])\n",
    "        tt.append(new)\n",
    "    return tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_enc = one_hot_encoder(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train_sentences_enc: \n",
      "5196 25\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(sentence) for sentence in train_sentences_enc])\n",
    "\n",
    "# padding\n",
    "def padding(data, pad, max_length):\n",
    "    '''\n",
    "    input:\n",
    "        - data in sentence\n",
    "        - pad: value to pad\n",
    "        - max_length: maximum length of the sentence\n",
    "    output:\n",
    "        - padded data\n",
    "    '''\n",
    "    padded_data = data\n",
    "    if len(padded_data) < max_length:\n",
    "        for _ in range(0, max_length - len(padded_data)):\n",
    "            padded_data.append(pad)\n",
    "    return padded_data\n",
    "\n",
    "train_sentences_enc = [padding(sen, -1, max_len) for sen in train_sentences_enc]\n",
    "\n",
    "print('size of train_sentences_enc: ')\n",
    "print(len(train_sentences_enc), len(train_sentences_enc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 introduce PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%pip install torch\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment to install pytorch\n",
    "'''\n",
    "%pip install torch\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch run successfully!\n"
     ]
    }
   ],
   "source": [
    "# hello pytorch!!\n",
    "import torch\n",
    "\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print('PyTorch run successfully!' if type(x_data) == torch.Tensor else 'FAILED!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 5\n",
    "\n",
    "embedding = nn.Embedding(num_vocab+2, embedding_dim)\n",
    "\n",
    "train_shape = (len(train_sentences_enc), max_len, embedding_dim)\n",
    "train_tensor = tensor(np.zeros(train_shape, dtype='float32'))\n",
    "\n",
    "for i, sen_enc in enumerate(train_sentences_enc):\n",
    "    for j, word_enc in enumerate(sen_enc):\n",
    "        train_tensor[i][j] = embedding(tensor(word_enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5196, 25, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 convolutional neural network (CNN)\n",
    "\n",
    "In this project, we will use convolutional neural network (CNN) for the sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyper parameters\n",
    "batch_size = 32\n",
    "embedding_dims = 300 #Length of the token vectors\n",
    "filters = 250 #number of filters in your Convnet\n",
    "kernel_size = 3 # a window size of 3 tokens\n",
    "hidden_dims = 250 #number of neurons at the normal feedforward NN\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [6, 3, 5], expected input[1, 25, 5] to have 3 channels, but got 25 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, sen)\n\u001b[0;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[0;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# flatten all dimensions except batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [6, 3, 5], expected input[1, 25, 5] to have 3 channels, but got 25 channels instead"
     ]
    }
   ],
   "source": [
    "# train \n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, sen in enumerate(train_tensor):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn(sen)\n",
    "        loss = criterion(outputs, sen)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict unseen text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
